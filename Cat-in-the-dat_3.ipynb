{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/cat_in_the_dat_train.csv', index_col='id')\n",
    "test = pd.read_csv('../data/cat_in_the_dat_test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>nom_4</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Bassoon</td>\n",
       "      <td>...</td>\n",
       "      <td>2f4cb3d51</td>\n",
       "      <td>2</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>D</td>\n",
       "      <td>kr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>f83c56c21</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>bF</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Theremin</td>\n",
       "      <td>...</td>\n",
       "      <td>ae6800dd0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>R</td>\n",
       "      <td>Jc</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>...</td>\n",
       "      <td>8270f0d71</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>i</td>\n",
       "      <td>D</td>\n",
       "      <td>kW</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>...</td>\n",
       "      <td>b164b72a7</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>qP</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bin_0  bin_1  bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "id                                                                        \n",
       "0       0      0      0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1       0      1      0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2       0      0      0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3       0      1      0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4       0      0      0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "       nom_4  ...      nom_9 ord_0        ord_1        ord_2 ord_3  ord_4  \\\n",
       "id            ...                                                           \n",
       "0    Bassoon  ...  2f4cb3d51     2  Grandmaster         Cold     h      D   \n",
       "1      Piano  ...  f83c56c21     1  Grandmaster          Hot     a      A   \n",
       "2   Theremin  ...  ae6800dd0     1       Expert     Lava Hot     h      R   \n",
       "3       Oboe  ...  8270f0d71     1  Grandmaster  Boiling Hot     i      D   \n",
       "4       Oboe  ...  b164b72a7     1  Grandmaster     Freezing     a      R   \n",
       "\n",
       "   ord_5 day month target  \n",
       "id                         \n",
       "0     kr   2     2      0  \n",
       "1     bF   7     8      0  \n",
       "2     Jc   7     2      0  \n",
       "3     kW   2     1      1  \n",
       "4     qP   7     8      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train['target']\n",
    "X = train.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OrdinalEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.ord_dict = {\n",
    "            \"ord_1\": {\n",
    "                \"Novice\": 1,\n",
    "                \"Contributor\": 2,\n",
    "                \"Expert\": 3,\n",
    "                \"Master\": 4,\n",
    "                \"Grandmaster\": 5        \n",
    "            },\n",
    "\n",
    "            \"ord_2\": {\n",
    "                \"Freezing\": 1,\n",
    "                \"Cold\": 2,\n",
    "                \"Warm\": 3,\n",
    "                \"Hot\": 4,\n",
    "                \"Boiling Hot\": 5,\n",
    "                \"Lava Hot\": 5\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        res = df\n",
    "        for col, mapping in self.ord_dict.items():\n",
    "            res[col] = res[col].map(mapping)\n",
    "        return res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeasonEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, month_num_col):\n",
    "        self.month_num_col = month_num_col\n",
    "\n",
    "    def __get_season(self, month_num):\n",
    "        if month_num in [12, 1, 2]:\n",
    "            return 'winter'\n",
    "        elif month_num in [3, 4, 5]:\n",
    "            return 'spring'\n",
    "        elif month_num in [6, 7, 8]:\n",
    "            return 'summer'\n",
    "        elif month_num in [9, 10, 11]:\n",
    "            return 'autumn'\n",
    "        else:\n",
    "            return 'error'\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        res = df\n",
    "        res['season'] = res[self.month_num_col].apply(self.__get_season)\n",
    "        return res      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_cols):\n",
    "        self.cat_cols = cat_cols\n",
    "        self.encoded = dict()\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        df_ = df.copy()\n",
    "        df_[self.cat_cols].fillna('nan', inplace=True)\n",
    "        df_['target'] = target\n",
    "        for col in self.cat_cols:\n",
    "            mapping = df_.groupby(col)['target'].mean()*100\n",
    "            self.encoded[col] = dict(mapping)\n",
    "        df_.drop('target', axis=1, inplace=True)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        res = df\n",
    "        res[self.cat_cols].fillna('nan', inplace=True)\n",
    "        for col, mapping in self.encoded.items():\n",
    "            res[col+'_mean'] = res[col].map(mapping)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BayesEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_cols):\n",
    "        self.cat_cols = cat_cols\n",
    "        self.encoded = dict()\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        df_ = df\n",
    "        df_[self.cat_cols].fillna('nan', inplace=True)\n",
    "        df_['target'] = target\n",
    "        global_pos_target = df_['target'].mean()\n",
    "        for col in self.cat_cols:\n",
    "            global_count = df_[col].count()\n",
    "            means = df_.groupby(col)['target'].mean()\n",
    "            probs = df_[col].value_counts()/global_count\n",
    "            mapping = (means*probs)*100/global_pos_target\n",
    "            self.encoded[col] = dict(mapping)\n",
    "        df_.drop('target', axis=1, inplace=True)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        res = df.copy()\n",
    "        res[self.cat_cols].fillna('nan', inplace=True)\n",
    "        for col, mapping in self.encoded.items():\n",
    "            res[col+'_bayes'] = res[col].map(mapping)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CombinationEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_features):\n",
    "        self.cat_features = cat_features\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        from itertools import combinations\n",
    "        res = df.copy()\n",
    "        for comb in combinations(self.cat_features, 2):\n",
    "            try:\n",
    "                res[comb[0]+'+'+comb[1]] = res[comb[0]]*res[comb[1]]\n",
    "            except:\n",
    "                continue\n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class LogisticEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.logit = LogisticRegression(n_jobs = -1, random_state = 17)\n",
    "        self.columns = None\n",
    "        \n",
    "    def fit(self, df, target=None):\n",
    "        df_ = df.select_dtypes(include=['int64', 'float64']).fillna(0)        \n",
    "        self.logit.fit(df_, y_train)\n",
    "        self.columns = df_.columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        res = df[self.columns].copy()\n",
    "        res['logit'] = self.logit.predict_proba(res.fillna(0))[:,1] \n",
    "        return res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = []\n",
    "for col in list(X_train.columns):\n",
    "    feat.append(col+'_mean')\n",
    "    feat.append(col+'_bayes')\n",
    "\n",
    "len(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1090"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "ordinal = OrdinalEncoder()\n",
    "logit = LogisticEncoder()\n",
    "combination = CombinationEncoder(feat)\n",
    "season = SeasonEncoder('month')\n",
    "mean = MeanEncoder(X.columns)\n",
    "bayes = BayesEncoder(X.columns)\n",
    "\n",
    "transformer_pipe = make_pipeline(season,\n",
    "                                 ordinal,\n",
    "                                 mean,\n",
    "                                 bayes,\n",
    "                                 combination,\n",
    "                                 logit)\n",
    "\n",
    "Xtrain_transform = transformer_pipe.fit_transform(X_train, y_train)\n",
    "\n",
    "len(Xtrain_transform.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.84 s, sys: 5.46 s, total: 8.3 s\n",
      "Wall time: 8.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Xtrain_transform = Xtrain_transform.select_dtypes(include=['int64', 'float64']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.85 s, sys: 11.9 s, total: 19.7 s\n",
      "Wall time: 12.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_test_transform = transformer_pipe.transform(X_test).select_dtypes(include=['int64', 'float64']).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090\n",
      "1090\n"
     ]
    }
   ],
   "source": [
    "print(len(Xtrain_transform.columns))\n",
    "print(len(X_test_transform.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>ord_1_mean</th>\n",
       "      <th>ord_0_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>ord_5_bayes+day_bayes</th>\n",
       "      <th>ord_5_bayes+month_mean</th>\n",
       "      <th>ord_5_bayes+month_bayes</th>\n",
       "      <th>day_mean+day_bayes</th>\n",
       "      <th>day_mean+month_mean</th>\n",
       "      <th>day_mean+month_bayes</th>\n",
       "      <th>day_bayes+month_mean</th>\n",
       "      <th>day_bayes+month_bayes</th>\n",
       "      <th>month_mean+month_bayes</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275061</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40.438841</td>\n",
       "      <td>27.750880</td>\n",
       "      <td>...</td>\n",
       "      <td>23.770265</td>\n",
       "      <td>24.797033</td>\n",
       "      <td>11.037467</td>\n",
       "      <td>824.310737</td>\n",
       "      <td>859.917234</td>\n",
       "      <td>382.759817</td>\n",
       "      <td>629.250904</td>\n",
       "      <td>280.087375</td>\n",
       "      <td>292.185883</td>\n",
       "      <td>0.246917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101025</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>24.157809</td>\n",
       "      <td>33.575256</td>\n",
       "      <td>...</td>\n",
       "      <td>12.571146</td>\n",
       "      <td>20.244317</td>\n",
       "      <td>4.146885</td>\n",
       "      <td>566.627801</td>\n",
       "      <td>912.485843</td>\n",
       "      <td>186.915372</td>\n",
       "      <td>658.650614</td>\n",
       "      <td>134.919271</td>\n",
       "      <td>217.271239</td>\n",
       "      <td>0.441129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75873</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24.157809</td>\n",
       "      <td>33.575256</td>\n",
       "      <td>...</td>\n",
       "      <td>8.738083</td>\n",
       "      <td>12.542737</td>\n",
       "      <td>3.038954</td>\n",
       "      <td>824.310737</td>\n",
       "      <td>1183.224342</td>\n",
       "      <td>286.680972</td>\n",
       "      <td>865.833312</td>\n",
       "      <td>209.780958</td>\n",
       "      <td>301.121803</td>\n",
       "      <td>0.607659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237475</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>27.724704</td>\n",
       "      <td>27.750880</td>\n",
       "      <td>...</td>\n",
       "      <td>25.879457</td>\n",
       "      <td>25.735601</td>\n",
       "      <td>12.703442</td>\n",
       "      <td>824.310737</td>\n",
       "      <td>819.728617</td>\n",
       "      <td>404.629193</td>\n",
       "      <td>599.842581</td>\n",
       "      <td>296.090455</td>\n",
       "      <td>294.444568</td>\n",
       "      <td>0.237476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237380</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>27.724704</td>\n",
       "      <td>39.602902</td>\n",
       "      <td>...</td>\n",
       "      <td>12.976401</td>\n",
       "      <td>32.545648</td>\n",
       "      <td>14.505548</td>\n",
       "      <td>284.171297</td>\n",
       "      <td>712.719873</td>\n",
       "      <td>317.658215</td>\n",
       "      <td>313.830305</td>\n",
       "      <td>139.873712</td>\n",
       "      <td>350.812258</td>\n",
       "      <td>0.441298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1090 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bin_0  bin_1  bin_2  ord_0  ord_1  ord_2  day  month  ord_1_mean  \\\n",
       "id                                                                         \n",
       "275061      0      0      0      1      5      1    1      1   40.438841   \n",
       "101025      0      0      0      2      1      5    3      8   24.157809   \n",
       "75873       0      0      0      2      1      5    1     10   24.157809   \n",
       "237475      0      0      0      1      2      2    1      2   27.724704   \n",
       "237380      0      0      0      3      2      5    4      3   27.724704   \n",
       "\n",
       "        ord_0_mean  ...  ord_5_bayes+day_bayes  ord_5_bayes+month_mean  \\\n",
       "id                  ...                                                  \n",
       "275061   27.750880  ...              23.770265               24.797033   \n",
       "101025   33.575256  ...              12.571146               20.244317   \n",
       "75873    33.575256  ...               8.738083               12.542737   \n",
       "237475   27.750880  ...              25.879457               25.735601   \n",
       "237380   39.602902  ...              12.976401               32.545648   \n",
       "\n",
       "        ord_5_bayes+month_bayes  day_mean+day_bayes  day_mean+month_mean  \\\n",
       "id                                                                         \n",
       "275061                11.037467          824.310737           859.917234   \n",
       "101025                 4.146885          566.627801           912.485843   \n",
       "75873                  3.038954          824.310737          1183.224342   \n",
       "237475                12.703442          824.310737           819.728617   \n",
       "237380                14.505548          284.171297           712.719873   \n",
       "\n",
       "        day_mean+month_bayes  day_bayes+month_mean  day_bayes+month_bayes  \\\n",
       "id                                                                          \n",
       "275061            382.759817            629.250904             280.087375   \n",
       "101025            186.915372            658.650614             134.919271   \n",
       "75873             286.680972            865.833312             209.780958   \n",
       "237475            404.629193            599.842581             296.090455   \n",
       "237380            317.658215            313.830305             139.873712   \n",
       "\n",
       "        month_mean+month_bayes     logit  \n",
       "id                                        \n",
       "275061              292.185883  0.246917  \n",
       "101025              217.271239  0.441129  \n",
       "75873               301.121803  0.607659  \n",
       "237475              294.444568  0.237476  \n",
       "237380              350.812258  0.441298  \n",
       "\n",
       "[5 rows x 1090 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=500, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lg = LGBMClassifier(n_jobs = -1, n_estimators=500)\n",
    "lg.fit(Xtrain_transform, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скор на обучающей выборке: 0.8964384333123749\n",
      "Скор на тестовой выборке: 0.7745324004557603\n"
     ]
    }
   ],
   "source": [
    "pred_test = lg.predict_proba(X_test_transform)[:, 1]\n",
    "pred_train = lg.predict_proba(Xtrain_transform)[:, 1]\n",
    "print(\"Скор на обучающей выборке: \" + str(roc_auc_score(y_train, pred_train)))\n",
    "print(\"Скор на тестовой выборке: \" + str(roc_auc_score(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, space_eval\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "def function(params):\n",
    "    params = {\n",
    "        'learning_rate': params['learning_rate'], \n",
    "        'max_depth': params['max_depth'], \n",
    "        'subsample': params['subsample'], # Доля фичей\n",
    "        'colsample_bytree': params['colsample_bytree'] # Доля объектов\n",
    "    }\n",
    "    \n",
    "    print(\"############## RUN ################\")\n",
    "    print(\"params = {params}\".format(params=params))\n",
    "    \n",
    "    LGBM = LGBMClassifier(\n",
    "        n_jobs=-1, \n",
    "        n_estimators=500,\n",
    "        verbose=200,\n",
    "        **params)\n",
    "    \n",
    "    LGBM.fit(Xtrain_transform, y_train)\n",
    "    pred = LGBM.predict_proba(X_test_transform)[:, 1]\n",
    "    score = roc_auc_score(y_test, pred)\n",
    "    print(\"Score: {score}\".format(score=str(score)))\n",
    "    \n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_space =  {\n",
    "            'learning_rate': hp.quniform('learning_rate', 0.1, 0.5, 0.1),\n",
    "            'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "            'subsample': hp.quniform('subsample', 0.5, 1, 0.1),\n",
    "            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## RUN ################                 \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.7000000000000001, 'max_depth': 2}\n",
      "Score: 0.7756181316460888                           \n",
      "############## RUN ################                                          \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.4, 'colsample_bytree': 0.9, 'max_depth': 3}\n",
      "Score: 0.7682477038991173                                                    \n",
      "############## RUN ################                                          \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.4, 'colsample_bytree': 0.7000000000000001, 'max_depth': 9}\n",
      "Score: 0.748760428001362                                                     \n",
      "############## RUN ################                                          \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.2, 'colsample_bytree': 0.8, 'max_depth': 2}\n",
      "Score: 0.7761671248140934                                                    \n",
      "############## RUN ################                                          \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.4, 'colsample_bytree': 1.0, 'max_depth': 11}\n",
      "Score: 0.7486309253872652                                                    \n",
      "############## RUN ################                                          \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.4, 'colsample_bytree': 0.9, 'max_depth': 4}\n",
      "Score: 0.759611103551246                                                     \n",
      "############## RUN ################                                          \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.5, 'colsample_bytree': 0.5, 'max_depth': 10}\n",
      "Score: 0.7397307662578168                                                    \n",
      "############## RUN ################                                          \n",
      "params = {'subsample': 0.5, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.8, 'max_depth': 6}\n",
      "Score: 0.75776964316685                                                      \n",
      "############## RUN ################                                          \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.5, 'colsample_bytree': 0.9, 'max_depth': 6}\n",
      "Score: 0.7397235780179235                                                    \n",
      "############## RUN ################                                          \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.8, 'max_depth': 8}\n",
      "Score: 0.7566054043272278                                                    \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.1, 'colsample_bytree': 1.0, 'max_depth': 10}\n",
      "Score: 0.7735430789368472                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.1, 'colsample_bytree': 0.8, 'max_depth': 7}\n",
      "Score: 0.7736886097714801                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.9, 'max_depth': 10}\n",
      "Score: 0.7568402349677958                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.8, 'max_depth': 2}\n",
      "Score: 0.7749122381286357                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.9, 'max_depth': 2}\n",
      "Score: 0.7744922178943219                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.4, 'colsample_bytree': 0.7000000000000001, 'max_depth': 1}\n",
      "Score: 0.7774565171410229                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.4, 'colsample_bytree': 0.9, 'max_depth': 2}\n",
      "Score: 0.7736138556034391                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.9, 'max_depth': 7}\n",
      "Score: 0.7573169355774411                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.7000000000000001, 'max_depth': 7}\n",
      "Score: 0.7575098672569305                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.4, 'colsample_bytree': 1.0, 'max_depth': 11}\n",
      "Score: 0.7486309253872652                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.2, 'colsample_bytree': 0.6000000000000001, 'max_depth': 1}\n",
      "Score: 0.7774286184625494                                                     \n",
      "############## RUN ################                                             \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.2, 'colsample_bytree': 0.5, 'max_depth': 1}\n",
      "Score: 0.777407318909633                                                        \n",
      "############## RUN ################                                             \n",
      "params = {'subsample': 0.5, 'learning_rate': 0.2, 'colsample_bytree': 0.6000000000000001, 'max_depth': 1}\n",
      "Score: 0.7774286184625494                                                       \n",
      "############## RUN ################                                             \n",
      "params = {'subsample': 0.5, 'learning_rate': 0.2, 'colsample_bytree': 0.6000000000000001, 'max_depth': 12}\n",
      "Score: 0.7662684221098268                                                       \n",
      "############## RUN ################                                             \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.1, 'colsample_bytree': 0.6000000000000001, 'max_depth': 1}\n",
      "Score: 0.777935582045454                                                        \n",
      "############## RUN ################                                             \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.5, 'colsample_bytree': 0.6000000000000001, 'max_depth': 13}\n",
      "Score: 0.7394115427026744                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.1, 'colsample_bytree': 0.5, 'max_depth': 5}\n",
      "Score: 0.7744550553602563                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.4, 'colsample_bytree': 0.7000000000000001, 'max_depth': 1}\n",
      "Score: 0.7774565171410229                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.5, 'colsample_bytree': 0.7000000000000001, 'max_depth': 1}\n",
      "Score: 0.7771820891346319                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.5, 'colsample_bytree': 0.6000000000000001, 'max_depth': 12}\n",
      "Score: 0.740236490218759                                                      \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.5, 'learning_rate': 0.4, 'colsample_bytree': 0.7000000000000001, 'max_depth': 3}\n",
      "Score: 0.7667148297026876                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.1, 'colsample_bytree': 0.5, 'max_depth': 9}\n",
      "Score: 0.773593661782863                                                      \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.4, 'colsample_bytree': 0.6000000000000001, 'max_depth': 1}\n",
      "Score: 0.7775086531066523                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.5, 'colsample_bytree': 0.6000000000000001, 'max_depth': 8}\n",
      "Score: 0.7432533159969132                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.4, 'colsample_bytree': 0.5, 'max_depth': 5}\n",
      "Score: 0.7514407721786771                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.2, 'colsample_bytree': 0.6000000000000001, 'max_depth': 4}\n",
      "Score: 0.771147662977877                                                      \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.5, 'colsample_bytree': 0.5, 'max_depth': 13}\n",
      "Score: 0.7421993270968854                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.4, 'colsample_bytree': 0.6000000000000001, 'max_depth': 3}\n",
      "Score: 0.7671741364176539                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.5, 'learning_rate': 0.1, 'colsample_bytree': 0.5, 'max_depth': 9}\n",
      "Score: 0.773593661782863                                                      \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.4, 'colsample_bytree': 0.7000000000000001, 'max_depth': 1}\n",
      "Score: 0.7774565171410229                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.2, 'colsample_bytree': 0.6000000000000001, 'max_depth': 6}\n",
      "Score: 0.7668054644861207                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.5, 'max_depth': 11}\n",
      "Score: 0.756927531001244                                                      \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.5, 'colsample_bytree': 0.7000000000000001, 'max_depth': 8}\n",
      "Score: 0.7395202153572115                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.1, 'colsample_bytree': 0.6000000000000001, 'max_depth': 4}\n",
      "Score: 0.7757070356612394                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.5, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.8, 'max_depth': 1}\n",
      "Score: 0.7773723168968801                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.4, 'colsample_bytree': 0.5, 'max_depth': 1}\n",
      "Score: 0.7775480728238062                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.5, 'colsample_bytree': 0.5, 'max_depth': 10}\n",
      "Score: 0.7397307649515765                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.5, 'max_depth': 6}\n",
      "Score: 0.7581459487661892                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.4, 'colsample_bytree': 0.5, 'max_depth': 12}\n",
      "Score: 0.7481262660120966                                                     \n",
      "############## RUN ################                                           \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.2, 'colsample_bytree': 0.8, 'max_depth': 13}\n",
      "Score: 0.7652024935211301                                                     \n",
      "100%|██████████| 50/50 [2:08:36<00:00, 156.87s/it, best loss: -0.777935582045]\n",
      "CPU times: user 1d 2h 46min 41s, sys: 1d 5h 21min 57s, total: 2d 8h 8min 38s\n",
      "Wall time: 2h 8min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "best = fmin(fn=function,\n",
    "            space=lgbm_space,\n",
    "            # tpe - Tree of Parzen Estimators (TPE)\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.6000000000000001,\n",
       " 'learning_rate': 0.1,\n",
       " 'max_depth': 1,\n",
       " 'subsample': 0.6000000000000001}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = space_eval(lgbm_space, best)\n",
    "#best_params['max_depth'] = int(best_params['max_depth'])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_params = {'colsample_bytree': 0.6000000000000001,\n",
    " 'learning_rate': 0.1,\n",
    " 'max_depth': 1,\n",
    " 'subsample': 0.6000000000000001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.703331\tvalid_0's binary_logloss: 0.598491\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's auc: 0.694438\tvalid_0's binary_logloss: 0.597258\n",
      "[3]\tvalid_0's auc: 0.698942\tvalid_0's binary_logloss: 0.595287\n",
      "[4]\tvalid_0's auc: 0.689653\tvalid_0's binary_logloss: 0.593811\n",
      "[5]\tvalid_0's auc: 0.681721\tvalid_0's binary_logloss: 0.592643\n",
      "[6]\tvalid_0's auc: 0.706484\tvalid_0's binary_logloss: 0.580388\n",
      "[7]\tvalid_0's auc: 0.700588\tvalid_0's binary_logloss: 0.579897\n",
      "[8]\tvalid_0's auc: 0.69656\tvalid_0's binary_logloss: 0.579136\n",
      "[9]\tvalid_0's auc: 0.692181\tvalid_0's binary_logloss: 0.578732\n",
      "[10]\tvalid_0's auc: 0.698158\tvalid_0's binary_logloss: 0.576487\n",
      "[11]\tvalid_0's auc: 0.709957\tvalid_0's binary_logloss: 0.567896\n",
      "[12]\tvalid_0's auc: 0.719338\tvalid_0's binary_logloss: 0.560347\n",
      "[13]\tvalid_0's auc: 0.722355\tvalid_0's binary_logloss: 0.559228\n",
      "[14]\tvalid_0's auc: 0.725388\tvalid_0's binary_logloss: 0.557982\n",
      "[15]\tvalid_0's auc: 0.728735\tvalid_0's binary_logloss: 0.556547\n",
      "[16]\tvalid_0's auc: 0.731233\tvalid_0's binary_logloss: 0.555105\n",
      "[17]\tvalid_0's auc: 0.737815\tvalid_0's binary_logloss: 0.549303\n",
      "[18]\tvalid_0's auc: 0.741877\tvalid_0's binary_logloss: 0.544796\n",
      "[19]\tvalid_0's auc: 0.743074\tvalid_0's binary_logloss: 0.544077\n",
      "[20]\tvalid_0's auc: 0.748074\tvalid_0's binary_logloss: 0.539832\n",
      "[21]\tvalid_0's auc: 0.748806\tvalid_0's binary_logloss: 0.53916\n",
      "[22]\tvalid_0's auc: 0.750237\tvalid_0's binary_logloss: 0.53824\n",
      "[23]\tvalid_0's auc: 0.75201\tvalid_0's binary_logloss: 0.535297\n",
      "[24]\tvalid_0's auc: 0.753036\tvalid_0's binary_logloss: 0.534651\n",
      "[25]\tvalid_0's auc: 0.756038\tvalid_0's binary_logloss: 0.53168\n",
      "[26]\tvalid_0's auc: 0.756376\tvalid_0's binary_logloss: 0.531299\n",
      "[27]\tvalid_0's auc: 0.758122\tvalid_0's binary_logloss: 0.529152\n",
      "[28]\tvalid_0's auc: 0.760628\tvalid_0's binary_logloss: 0.526854\n",
      "[29]\tvalid_0's auc: 0.762128\tvalid_0's binary_logloss: 0.525029\n",
      "[30]\tvalid_0's auc: 0.763205\tvalid_0's binary_logloss: 0.523599\n",
      "[31]\tvalid_0's auc: 0.763591\tvalid_0's binary_logloss: 0.523249\n",
      "[32]\tvalid_0's auc: 0.765276\tvalid_0's binary_logloss: 0.521731\n",
      "[33]\tvalid_0's auc: 0.765915\tvalid_0's binary_logloss: 0.520725\n",
      "[34]\tvalid_0's auc: 0.767131\tvalid_0's binary_logloss: 0.519518\n",
      "[35]\tvalid_0's auc: 0.767529\tvalid_0's binary_logloss: 0.518849\n",
      "[36]\tvalid_0's auc: 0.76795\tvalid_0's binary_logloss: 0.518564\n",
      "[37]\tvalid_0's auc: 0.768321\tvalid_0's binary_logloss: 0.518253\n",
      "[38]\tvalid_0's auc: 0.768637\tvalid_0's binary_logloss: 0.517981\n",
      "[39]\tvalid_0's auc: 0.768997\tvalid_0's binary_logloss: 0.517672\n",
      "[40]\tvalid_0's auc: 0.769244\tvalid_0's binary_logloss: 0.517485\n",
      "[41]\tvalid_0's auc: 0.768417\tvalid_0's binary_logloss: 0.517852\n",
      "[42]\tvalid_0's auc: 0.769399\tvalid_0's binary_logloss: 0.516947\n",
      "[43]\tvalid_0's auc: 0.769757\tvalid_0's binary_logloss: 0.516418\n",
      "[44]\tvalid_0's auc: 0.769927\tvalid_0's binary_logloss: 0.516273\n",
      "[45]\tvalid_0's auc: 0.770762\tvalid_0's binary_logloss: 0.515511\n",
      "[46]\tvalid_0's auc: 0.771033\tvalid_0's binary_logloss: 0.515092\n",
      "[47]\tvalid_0's auc: 0.771619\tvalid_0's binary_logloss: 0.514487\n",
      "[48]\tvalid_0's auc: 0.77194\tvalid_0's binary_logloss: 0.51431\n",
      "[49]\tvalid_0's auc: 0.772132\tvalid_0's binary_logloss: 0.513999\n",
      "[50]\tvalid_0's auc: 0.772553\tvalid_0's binary_logloss: 0.513562\n",
      "[51]\tvalid_0's auc: 0.772819\tvalid_0's binary_logloss: 0.513224\n",
      "[52]\tvalid_0's auc: 0.773023\tvalid_0's binary_logloss: 0.513056\n",
      "[53]\tvalid_0's auc: 0.772589\tvalid_0's binary_logloss: 0.513356\n",
      "[54]\tvalid_0's auc: 0.772694\tvalid_0's binary_logloss: 0.513213\n",
      "[55]\tvalid_0's auc: 0.773014\tvalid_0's binary_logloss: 0.512902\n",
      "[56]\tvalid_0's auc: 0.773158\tvalid_0's binary_logloss: 0.512782\n",
      "[57]\tvalid_0's auc: 0.773242\tvalid_0's binary_logloss: 0.512644\n",
      "[58]\tvalid_0's auc: 0.773404\tvalid_0's binary_logloss: 0.512704\n",
      "[59]\tvalid_0's auc: 0.773034\tvalid_0's binary_logloss: 0.51298\n",
      "[60]\tvalid_0's auc: 0.773106\tvalid_0's binary_logloss: 0.512861\n",
      "[61]\tvalid_0's auc: 0.773212\tvalid_0's binary_logloss: 0.512774\n",
      "[62]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.512566\n",
      "[63]\tvalid_0's auc: 0.773597\tvalid_0's binary_logloss: 0.512698\n",
      "[64]\tvalid_0's auc: 0.773274\tvalid_0's binary_logloss: 0.51297\n",
      "[65]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.512824\n",
      "[66]\tvalid_0's auc: 0.773492\tvalid_0's binary_logloss: 0.51275\n",
      "[67]\tvalid_0's auc: 0.773637\tvalid_0's binary_logloss: 0.512626\n",
      "[68]\tvalid_0's auc: 0.773663\tvalid_0's binary_logloss: 0.512603\n",
      "[69]\tvalid_0's auc: 0.773769\tvalid_0's binary_logloss: 0.512709\n",
      "[70]\tvalid_0's auc: 0.773477\tvalid_0's binary_logloss: 0.513012\n",
      "[71]\tvalid_0's auc: 0.773554\tvalid_0's binary_logloss: 0.512944\n",
      "[72]\tvalid_0's auc: 0.773589\tvalid_0's binary_logloss: 0.513053\n",
      "[73]\tvalid_0's auc: 0.773716\tvalid_0's binary_logloss: 0.512967\n",
      "[74]\tvalid_0's auc: 0.773443\tvalid_0's binary_logloss: 0.513273\n",
      "[75]\tvalid_0's auc: 0.773458\tvalid_0's binary_logloss: 0.513267\n",
      "[76]\tvalid_0's auc: 0.773189\tvalid_0's binary_logloss: 0.513582\n",
      "[77]\tvalid_0's auc: 0.773306\tvalid_0's binary_logloss: 0.513509\n",
      "[78]\tvalid_0's auc: 0.773311\tvalid_0's binary_logloss: 0.513516\n",
      "[79]\tvalid_0's auc: 0.773374\tvalid_0's binary_logloss: 0.513479\n",
      "[80]\tvalid_0's auc: 0.77349\tvalid_0's binary_logloss: 0.51367\n",
      "[81]\tvalid_0's auc: 0.773575\tvalid_0's binary_logloss: 0.513627\n",
      "[82]\tvalid_0's auc: 0.77358\tvalid_0's binary_logloss: 0.513656\n",
      "[83]\tvalid_0's auc: 0.773673\tvalid_0's binary_logloss: 0.513594\n",
      "[84]\tvalid_0's auc: 0.773915\tvalid_0's binary_logloss: 0.513314\n",
      "[85]\tvalid_0's auc: 0.773977\tvalid_0's binary_logloss: 0.513472\n",
      "[86]\tvalid_0's auc: 0.773731\tvalid_0's binary_logloss: 0.5138\n",
      "[87]\tvalid_0's auc: 0.773735\tvalid_0's binary_logloss: 0.513819\n",
      "[88]\tvalid_0's auc: 0.773791\tvalid_0's binary_logloss: 0.513875\n",
      "[89]\tvalid_0's auc: 0.773869\tvalid_0's binary_logloss: 0.51382\n",
      "[90]\tvalid_0's auc: 0.774155\tvalid_0's binary_logloss: 0.513466\n",
      "[91]\tvalid_0's auc: 0.774432\tvalid_0's binary_logloss: 0.513131\n",
      "[92]\tvalid_0's auc: 0.774502\tvalid_0's binary_logloss: 0.513311\n",
      "[93]\tvalid_0's auc: 0.774268\tvalid_0's binary_logloss: 0.513647\n",
      "[94]\tvalid_0's auc: 0.774268\tvalid_0's binary_logloss: 0.513672\n",
      "[95]\tvalid_0's auc: 0.774483\tvalid_0's binary_logloss: 0.513384\n",
      "[96]\tvalid_0's auc: 0.774541\tvalid_0's binary_logloss: 0.513343\n",
      "[97]\tvalid_0's auc: 0.774605\tvalid_0's binary_logloss: 0.5133\n",
      "[98]\tvalid_0's auc: 0.774805\tvalid_0's binary_logloss: 0.51307\n",
      "[99]\tvalid_0's auc: 0.774817\tvalid_0's binary_logloss: 0.513173\n",
      "[100]\tvalid_0's auc: 0.774898\tvalid_0's binary_logloss: 0.513341\n",
      "[101]\tvalid_0's auc: 0.774896\tvalid_0's binary_logloss: 0.513376\n",
      "[102]\tvalid_0's auc: 0.775139\tvalid_0's binary_logloss: 0.513067\n",
      "[103]\tvalid_0's auc: 0.775179\tvalid_0's binary_logloss: 0.51304\n",
      "[104]\tvalid_0's auc: 0.775245\tvalid_0's binary_logloss: 0.513118\n",
      "[105]\tvalid_0's auc: 0.775243\tvalid_0's binary_logloss: 0.513153\n",
      "[106]\tvalid_0's auc: 0.775444\tvalid_0's binary_logloss: 0.512877\n",
      "[107]\tvalid_0's auc: 0.77548\tvalid_0's binary_logloss: 0.512852\n",
      "[108]\tvalid_0's auc: 0.775492\tvalid_0's binary_logloss: 0.512983\n",
      "[109]\tvalid_0's auc: 0.775549\tvalid_0's binary_logloss: 0.513146\n",
      "[110]\tvalid_0's auc: 0.775743\tvalid_0's binary_logloss: 0.512874\n",
      "[111]\tvalid_0's auc: 0.775768\tvalid_0's binary_logloss: 0.512883\n",
      "[112]\tvalid_0's auc: 0.775765\tvalid_0's binary_logloss: 0.512923\n",
      "[113]\tvalid_0's auc: 0.775808\tvalid_0's binary_logloss: 0.513059\n",
      "[114]\tvalid_0's auc: 0.776031\tvalid_0's binary_logloss: 0.512766\n",
      "[115]\tvalid_0's auc: 0.776029\tvalid_0's binary_logloss: 0.512788\n",
      "[116]\tvalid_0's auc: 0.776056\tvalid_0's binary_logloss: 0.512773\n",
      "[117]\tvalid_0's auc: 0.77584\tvalid_0's binary_logloss: 0.513119\n",
      "[118]\tvalid_0's auc: 0.776064\tvalid_0's binary_logloss: 0.512842\n",
      "[119]\tvalid_0's auc: 0.775851\tvalid_0's binary_logloss: 0.513193\n",
      "[120]\tvalid_0's auc: 0.775873\tvalid_0's binary_logloss: 0.513323\n",
      "[121]\tvalid_0's auc: 0.775873\tvalid_0's binary_logloss: 0.513384\n",
      "[122]\tvalid_0's auc: 0.775895\tvalid_0's binary_logloss: 0.513375\n",
      "[123]\tvalid_0's auc: 0.776138\tvalid_0's binary_logloss: 0.513069\n",
      "[124]\tvalid_0's auc: 0.776185\tvalid_0's binary_logloss: 0.513207\n",
      "[125]\tvalid_0's auc: 0.776355\tvalid_0's binary_logloss: 0.512959\n",
      "[126]\tvalid_0's auc: 0.776352\tvalid_0's binary_logloss: 0.512986\n",
      "[127]\tvalid_0's auc: 0.7764\tvalid_0's binary_logloss: 0.513075\n",
      "[128]\tvalid_0's auc: 0.776422\tvalid_0's binary_logloss: 0.513058\n",
      "[129]\tvalid_0's auc: 0.776428\tvalid_0's binary_logloss: 0.513127\n",
      "[130]\tvalid_0's auc: 0.776619\tvalid_0's binary_logloss: 0.512871\n",
      "[131]\tvalid_0's auc: 0.776413\tvalid_0's binary_logloss: 0.513227\n",
      "[132]\tvalid_0's auc: 0.776568\tvalid_0's binary_logloss: 0.513002\n",
      "[133]\tvalid_0's auc: 0.776368\tvalid_0's binary_logloss: 0.513361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[134]\tvalid_0's auc: 0.776399\tvalid_0's binary_logloss: 0.513501\n",
      "[135]\tvalid_0's auc: 0.776396\tvalid_0's binary_logloss: 0.51353\n",
      "[136]\tvalid_0's auc: 0.776413\tvalid_0's binary_logloss: 0.513515\n",
      "[137]\tvalid_0's auc: 0.776439\tvalid_0's binary_logloss: 0.513566\n",
      "[138]\tvalid_0's auc: 0.776442\tvalid_0's binary_logloss: 0.513662\n",
      "[139]\tvalid_0's auc: 0.776592\tvalid_0's binary_logloss: 0.513439\n",
      "[140]\tvalid_0's auc: 0.77659\tvalid_0's binary_logloss: 0.513469\n",
      "[141]\tvalid_0's auc: 0.776761\tvalid_0's binary_logloss: 0.513235\n",
      "[142]\tvalid_0's auc: 0.776772\tvalid_0's binary_logloss: 0.513225\n",
      "[143]\tvalid_0's auc: 0.776816\tvalid_0's binary_logloss: 0.513194\n",
      "[144]\tvalid_0's auc: 0.776626\tvalid_0's binary_logloss: 0.513557\n",
      "[145]\tvalid_0's auc: 0.776646\tvalid_0's binary_logloss: 0.513678\n",
      "[146]\tvalid_0's auc: 0.776655\tvalid_0's binary_logloss: 0.513672\n",
      "[147]\tvalid_0's auc: 0.776655\tvalid_0's binary_logloss: 0.513719\n",
      "[148]\tvalid_0's auc: 0.776801\tvalid_0's binary_logloss: 0.513505\n",
      "[149]\tvalid_0's auc: 0.776827\tvalid_0's binary_logloss: 0.513624\n",
      "[150]\tvalid_0's auc: 0.77695\tvalid_0's binary_logloss: 0.513434\n",
      "[151]\tvalid_0's auc: 0.776949\tvalid_0's binary_logloss: 0.513464\n",
      "[152]\tvalid_0's auc: 0.776975\tvalid_0's binary_logloss: 0.513535\n",
      "[153]\tvalid_0's auc: 0.776982\tvalid_0's binary_logloss: 0.513532\n",
      "[154]\tvalid_0's auc: 0.777126\tvalid_0's binary_logloss: 0.513342\n",
      "[155]\tvalid_0's auc: 0.776985\tvalid_0's binary_logloss: 0.513574\n",
      "[156]\tvalid_0's auc: 0.776996\tvalid_0's binary_logloss: 0.513673\n",
      "[157]\tvalid_0's auc: 0.777036\tvalid_0's binary_logloss: 0.513648\n",
      "[158]\tvalid_0's auc: 0.777035\tvalid_0's binary_logloss: 0.513678\n",
      "[159]\tvalid_0's auc: 0.777189\tvalid_0's binary_logloss: 0.513466\n",
      "[160]\tvalid_0's auc: 0.777016\tvalid_0's binary_logloss: 0.513834\n",
      "[161]\tvalid_0's auc: 0.777025\tvalid_0's binary_logloss: 0.513834\n",
      "[162]\tvalid_0's auc: 0.777141\tvalid_0's binary_logloss: 0.513655\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.773449\tvalid_0's binary_logloss: 0.512566\n",
      "CPU times: user 4min 48s, sys: 4min 41s, total: 9min 29s\n",
      "Wall time: 36.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "LGBM = LGBMClassifier(\n",
    "        n_jobs=-1, \n",
    "        n_estimators=5000,\n",
    "        verbose=100,\n",
    "        **best_params\n",
    ")\n",
    "\n",
    "LGBM.fit(Xtrain_transform, \n",
    "         y_train,\n",
    "        eval_metric=['auc'],\n",
    "        eval_set=[(X_test_transform, y_test)],\n",
    "        early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.7 s, sys: 25.7 s, total: 41.4 s\n",
      "Wall time: 33.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test = pd.read_csv('../data/cat_in_the_dat_test.csv', index_col='id')\n",
    "test_transformed = transformer_pipe.transform(test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>ord_1_mean</th>\n",
       "      <th>ord_0_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>ord_5_bayes+day_bayes</th>\n",
       "      <th>ord_5_bayes+month_mean</th>\n",
       "      <th>ord_5_bayes+month_bayes</th>\n",
       "      <th>day_mean+day_bayes</th>\n",
       "      <th>day_mean+month_mean</th>\n",
       "      <th>day_mean+month_bayes</th>\n",
       "      <th>day_bayes+month_mean</th>\n",
       "      <th>day_bayes+month_bayes</th>\n",
       "      <th>month_mean+month_bayes</th>\n",
       "      <th>logit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300000</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>24.157809</td>\n",
       "      <td>33.575256</td>\n",
       "      <td>...</td>\n",
       "      <td>4.115600</td>\n",
       "      <td>27.893618</td>\n",
       "      <td>7.821422</td>\n",
       "      <td>147.655597</td>\n",
       "      <td>1000.740708</td>\n",
       "      <td>280.609555</td>\n",
       "      <td>194.216735</td>\n",
       "      <td>54.458734</td>\n",
       "      <td>369.095873</td>\n",
       "      <td>0.157204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300001</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>35.396896</td>\n",
       "      <td>27.750880</td>\n",
       "      <td>...</td>\n",
       "      <td>5.208623</td>\n",
       "      <td>13.362723</td>\n",
       "      <td>1.597319</td>\n",
       "      <td>417.364351</td>\n",
       "      <td>1070.748195</td>\n",
       "      <td>127.992352</td>\n",
       "      <td>387.261156</td>\n",
       "      <td>46.291431</td>\n",
       "      <td>118.760661</td>\n",
       "      <td>0.669516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300002</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>31.788113</td>\n",
       "      <td>33.575256</td>\n",
       "      <td>...</td>\n",
       "      <td>29.796529</td>\n",
       "      <td>42.987248</td>\n",
       "      <td>11.798215</td>\n",
       "      <td>824.310737</td>\n",
       "      <td>1189.227441</td>\n",
       "      <td>326.393562</td>\n",
       "      <td>870.226124</td>\n",
       "      <td>238.840944</td>\n",
       "      <td>344.574189</td>\n",
       "      <td>0.057692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>27.724704</td>\n",
       "      <td>27.750880</td>\n",
       "      <td>...</td>\n",
       "      <td>22.840268</td>\n",
       "      <td>24.590895</td>\n",
       "      <td>10.960126</td>\n",
       "      <td>836.331896</td>\n",
       "      <td>900.433843</td>\n",
       "      <td>401.322059</td>\n",
       "      <td>731.072399</td>\n",
       "      <td>325.837909</td>\n",
       "      <td>350.812258</td>\n",
       "      <td>0.536835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300004</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>40.438841</td>\n",
       "      <td>39.602902</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833748</td>\n",
       "      <td>15.677796</td>\n",
       "      <td>4.396083</td>\n",
       "      <td>284.171297</td>\n",
       "      <td>921.682305</td>\n",
       "      <td>258.441432</td>\n",
       "      <td>405.842253</td>\n",
       "      <td>113.798922</td>\n",
       "      <td>369.095873</td>\n",
       "      <td>0.837705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1090 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        bin_0  bin_1  bin_2  ord_0  ord_1  ord_2  day  month  ord_1_mean  \\\n",
       "id                                                                         \n",
       "300000      0      0      1      2      1      3    5     11   24.157809   \n",
       "300001      0      0      0      1      4      5    7      5   35.396896   \n",
       "300002      1      0      1      2      3      1    1     12   31.788113   \n",
       "300003      0      0      1      1      2      5    2      3   27.724704   \n",
       "300004      0      1      1      3      5      5    4     11   40.438841   \n",
       "\n",
       "        ord_0_mean  ...  ord_5_bayes+day_bayes  ord_5_bayes+month_mean  \\\n",
       "id                  ...                                                  \n",
       "300000   33.575256  ...               4.115600               27.893618   \n",
       "300001   27.750880  ...               5.208623               13.362723   \n",
       "300002   33.575256  ...              29.796529               42.987248   \n",
       "300003   27.750880  ...              22.840268               24.590895   \n",
       "300004   39.602902  ...               4.833748               15.677796   \n",
       "\n",
       "        ord_5_bayes+month_bayes  day_mean+day_bayes  day_mean+month_mean  \\\n",
       "id                                                                         \n",
       "300000                 7.821422          147.655597          1000.740708   \n",
       "300001                 1.597319          417.364351          1070.748195   \n",
       "300002                11.798215          824.310737          1189.227441   \n",
       "300003                10.960126          836.331896           900.433843   \n",
       "300004                 4.396083          284.171297           921.682305   \n",
       "\n",
       "        day_mean+month_bayes  day_bayes+month_mean  day_bayes+month_bayes  \\\n",
       "id                                                                          \n",
       "300000            280.609555            194.216735              54.458734   \n",
       "300001            127.992352            387.261156              46.291431   \n",
       "300002            326.393562            870.226124             238.840944   \n",
       "300003            401.322059            731.072399             325.837909   \n",
       "300004            258.441432            405.842253             113.798922   \n",
       "\n",
       "        month_mean+month_bayes     logit  \n",
       "id                                        \n",
       "300000              369.095873  0.157204  \n",
       "300001              118.760661  0.669516  \n",
       "300002              344.574189  0.057692  \n",
       "300003              350.812258  0.536835  \n",
       "300004              369.095873  0.837705  \n",
       "\n",
       "[5 rows x 1090 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16738353, 0.58389217, 0.06968382, ..., 0.4052507 , 0.61412092,\n",
       "       0.17989489])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = LGBM.predict_proba(test_transformed)[:,1] \n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>0.167384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300001</td>\n",
       "      <td>0.583892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300002</td>\n",
       "      <td>0.069684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300003</td>\n",
       "      <td>0.559533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300004</td>\n",
       "      <td>0.774823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    target\n",
       "0  300000  0.167384\n",
       "1  300001  0.583892\n",
       "2  300002  0.069684\n",
       "3  300003  0.559533\n",
       "4  300004  0.774823"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../data/cat_in_the_dat_test.csv')\n",
    "test[\"target\"] = y_preds\n",
    "submission = test[[\"id\", \"target\"]]\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../data/cat_in_the_dat_sub_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
