{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noize = np.random.uniform(size=5)\n",
    "noize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/cat_in_the_dat_train.csv', index_col='id')\n",
    "test = pd.read_csv('../data/cat_in_the_dat_test.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bin_0</th>\n",
       "      <th>bin_1</th>\n",
       "      <th>bin_2</th>\n",
       "      <th>bin_3</th>\n",
       "      <th>bin_4</th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>nom_4</th>\n",
       "      <th>...</th>\n",
       "      <th>nom_9</th>\n",
       "      <th>ord_0</th>\n",
       "      <th>ord_1</th>\n",
       "      <th>ord_2</th>\n",
       "      <th>ord_3</th>\n",
       "      <th>ord_4</th>\n",
       "      <th>ord_5</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Triangle</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Finland</td>\n",
       "      <td>Bassoon</td>\n",
       "      <td>...</td>\n",
       "      <td>2f4cb3d51</td>\n",
       "      <td>2</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Cold</td>\n",
       "      <td>h</td>\n",
       "      <td>D</td>\n",
       "      <td>kr</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>T</td>\n",
       "      <td>Y</td>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Hamster</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Piano</td>\n",
       "      <td>...</td>\n",
       "      <td>f83c56c21</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Hot</td>\n",
       "      <td>a</td>\n",
       "      <td>A</td>\n",
       "      <td>bF</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Theremin</td>\n",
       "      <td>...</td>\n",
       "      <td>ae6800dd0</td>\n",
       "      <td>1</td>\n",
       "      <td>Expert</td>\n",
       "      <td>Lava Hot</td>\n",
       "      <td>h</td>\n",
       "      <td>R</td>\n",
       "      <td>Jc</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>Y</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>...</td>\n",
       "      <td>8270f0d71</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Boiling Hot</td>\n",
       "      <td>i</td>\n",
       "      <td>D</td>\n",
       "      <td>kW</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>...</td>\n",
       "      <td>b164b72a7</td>\n",
       "      <td>1</td>\n",
       "      <td>Grandmaster</td>\n",
       "      <td>Freezing</td>\n",
       "      <td>a</td>\n",
       "      <td>R</td>\n",
       "      <td>qP</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bin_0  bin_1  bin_2 bin_3 bin_4  nom_0      nom_1    nom_2    nom_3  \\\n",
       "id                                                                        \n",
       "0       0      0      0     T     Y  Green   Triangle    Snake  Finland   \n",
       "1       0      1      0     T     Y  Green  Trapezoid  Hamster   Russia   \n",
       "2       0      0      0     F     Y   Blue  Trapezoid     Lion   Russia   \n",
       "3       0      1      0     F     Y    Red  Trapezoid    Snake   Canada   \n",
       "4       0      0      0     F     N    Red  Trapezoid     Lion   Canada   \n",
       "\n",
       "       nom_4  ...      nom_9 ord_0        ord_1        ord_2 ord_3  ord_4  \\\n",
       "id            ...                                                           \n",
       "0    Bassoon  ...  2f4cb3d51     2  Grandmaster         Cold     h      D   \n",
       "1      Piano  ...  f83c56c21     1  Grandmaster          Hot     a      A   \n",
       "2   Theremin  ...  ae6800dd0     1       Expert     Lava Hot     h      R   \n",
       "3       Oboe  ...  8270f0d71     1  Grandmaster  Boiling Hot     i      D   \n",
       "4       Oboe  ...  b164b72a7     1  Grandmaster     Freezing     a      R   \n",
       "\n",
       "   ord_5 day month target  \n",
       "id                         \n",
       "0     kr   2     2      0  \n",
       "1     bF   7     8      0  \n",
       "2     Jc   7     2      0  \n",
       "3     kW   2     1      1  \n",
       "4     qP   7     8      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = train['target']\n",
    "X = train.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CombinationEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_features):\n",
    "        self.cat_features = cat_features\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        from itertools import combinations\n",
    "        res = df\n",
    "        for comb in combinations(self.cat_features, 2):\n",
    "            res[comb[0]+'+'+comb[1]] = res[comb[0]].map(str) + '+' + res[comb[1]].map(str)\n",
    "        return res        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SeasonEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, month_num_col):\n",
    "        self.month_num_col = month_num_col\n",
    "\n",
    "    def __get_season(self, month_num):\n",
    "        if month_num in [12, 1, 2]:\n",
    "            return 'winter'\n",
    "        elif month_num in [3, 4, 5]:\n",
    "            return 'spring'\n",
    "        elif month_num in [6, 7, 8]:\n",
    "            return 'summer'\n",
    "        elif month_num in [9, 10, 11]:\n",
    "            return 'autumn'\n",
    "        else:\n",
    "            return 'error'\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        res = df\n",
    "        res['season'] = res[self.month_num_col].apply(self.__get_season)\n",
    "        return res      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CountEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_cols):\n",
    "        self.cat_cols = cat_cols\n",
    "        self.encoded = dict()\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        for col in self.cat_cols:\n",
    "            mapping = df[col].value_counts()\n",
    "            mapping['nan'] = df[col].isnull().sum()\n",
    "            self.encoded[col] = dict(mapping)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        res = df\n",
    "        res[self.cat_cols].fillna('nan', inplace=True)\n",
    "        for col, mapping in self.encoded.items():\n",
    "            res[col+'_counter'] = res[col].map(mapping)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MeanEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_cols):\n",
    "        self.cat_cols = cat_cols\n",
    "        self.encoded = dict()\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        df_ = df\n",
    "        df_[self.cat_cols].fillna('nan', inplace=True)\n",
    "        df_['target'] = target\n",
    "        for col in self.cat_cols:\n",
    "            mapping = df_.groupby(col)['target'].mean()\n",
    "            self.encoded[col] = dict(mapping)\n",
    "        df_.drop('target', axis=1, inplace=True)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        res = df\n",
    "        res[self.cat_cols].fillna('nan', inplace=True)\n",
    "        for col, mapping in self.encoded.items():\n",
    "            res[col+'_mean'] = res[col].map(mapping)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BayesEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_cols):\n",
    "        self.cat_cols = cat_cols\n",
    "        self.encoded = dict()\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        df_ = df\n",
    "        df_[self.cat_cols].fillna('nan', inplace=True)\n",
    "        df_['target'] = target\n",
    "        global_pos_target = df_['target'].mean()\n",
    "        for col in self.cat_cols:\n",
    "            global_count = df_[col].count()\n",
    "            means = df_.groupby(col)['target'].mean()\n",
    "            probs = df_[col].value_counts()/global_count\n",
    "            mapping = (means*probs)/global_pos_target\n",
    "            self.encoded[col] = dict(mapping)\n",
    "        df_.drop('target', axis=1, inplace=True)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        res = df.copy()\n",
    "        res[self.cat_cols].fillna('nan', inplace=True)\n",
    "        for col, mapping in self.encoded.items():\n",
    "            res[col+'_bayes'] = res[col].map(mapping)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RareEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cat_cols):\n",
    "        self.cat_cols = cat_cols\n",
    "        self.encoded = dict()\n",
    "\n",
    "    def __set_value(self, col, treshold):\n",
    "        if col < treshold:\n",
    "            return 0\n",
    "        else:\n",
    "            return col\n",
    "\n",
    "    def fit(self, df, target=None):\n",
    "        df_ = df.copy()\n",
    "        df_[self.cat_cols].fillna('nan', inplace=True)\n",
    "        for col in self.cat_cols:\n",
    "            treshold = df_[col].quantile(0.25)\n",
    "            self.encoded[col] = treshold\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        res = df.copy()\n",
    "        res[self.cat_cols].fillna('nan', inplace=True)\n",
    "        for col, treshold in self.encoded.items():\n",
    "            res[col] = res[col].apply(self.__set_value, treshold=treshold)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "features = list(X.columns)\n",
    "for comb in combinations(X.columns, 2):\n",
    "    f = comb[0]+'+'+comb[1]\n",
    "    features.append(f)\n",
    "\n",
    "#features = X.columns\n",
    "\n",
    "feat = []\n",
    "for col in list(features):\n",
    "    if '+' in col:\n",
    "        #feat.append(col+'_counter')\n",
    "        #feat.append(col+'_bayes')\n",
    "        feat.append(col+'_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/makilins/.local/lib/python2.7/site-packages/pandas/core/frame.py:4034: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/makilins/.local/lib/python2.7/site-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n",
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "553"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "combination = CombinationEncoder(X.columns)\n",
    "season = SeasonEncoder('month')\n",
    "count = CountEncoder(features)\n",
    "mean = MeanEncoder(features)\n",
    "bayes = BayesEncoder(features)\n",
    "rare = RareEncoder(feat)\n",
    "\n",
    "'''\n",
    "transformer_pipe = make_pipeline(combination,\n",
    "                                 season,\n",
    "                                 count,\n",
    "                                 mean,\n",
    "                                 bayes,\n",
    "                                 rare)\n",
    "'''\n",
    "transformer_pipe = make_pipeline(combination,\n",
    "                                 season,\n",
    "                                 mean,\n",
    "                                 rare)\n",
    "\n",
    "Xtrain_transform = transformer_pipe.fit_transform(X_train, y_train)\n",
    "\n",
    "len(Xtrain_transform.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 240000 entries, 169336 to 64753\n",
      "Columns: 553 entries, bin_0 to nom_8+day_mean\n",
      "dtypes: float64(276), int64(6), object(271)\n",
      "memory usage: 1014.4+ MB\n"
     ]
    }
   ],
   "source": [
    "Xtrain_transform.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 s, sys: 1.04 s, total: 2.19 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Xtrain_transform = Xtrain_transform.select_dtypes(include=['int64', 'float64']).fillna(0)\n",
    "#Xtrain_transform.to_csv('../data/cat_in_the_dat_train_transform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/Anaconda3-4.4.0/lib/python2.7/site-packages/ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_test_transform = transformer_pipe.transform(X_test).select_dtypes(include=['int64', 'float64']).fillna(0)\n",
    "#X_test_transform.to_csv('../data/cat_in_the_dat_test_transform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(len(Xtrain_transform.columns))\n",
    "print(len(X_test_transform.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat = []\n",
    "\n",
    "\n",
    "for col in list(X_test_transform.columns):\n",
    "    if '_counter' in col:\n",
    "        feat.append(col)\n",
    "    elif 'season' in col:\n",
    "        feat.append(col)\n",
    "    elif '_mean' in col:\n",
    "        feat.append(col)\n",
    "    elif '_bayes' in col:\n",
    "        feat.append(col)\n",
    "\n",
    "len(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lg = LGBMClassifier(n_jobs = -1, n_estimators=500)\n",
    "lg.fit(Xtrain_transform[feat], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test = lg.predict_proba(X_test_transform[feat])[:, 1]\n",
    "pred_train = lg.predict_proba(Xtrain_transform[feat])[:, 1]\n",
    "print(\"Скор на обучающей выборке: \" + str(roc_auc_score(y_train, pred_train)))\n",
    "print(\"Скор на тестовой выборке: \" + str(roc_auc_score(y_test, pred_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bayes\n",
    "Скор на обучающей выборке: 0.8322585823311461\n",
    "Скор на тестовой выборке: 0.7635748176349875\n",
    "\n",
    "mean\n",
    "Скор на обучающей выборке: 0.8734181185441837\n",
    "Скор на тестовой выборке: 0.7748761375678637\n",
    "\n",
    "counter\n",
    "Скор на обучающей выборке: 0.8140289870128897\n",
    "Скор на тестовой выборке: 0.7684248770966747\n",
    "\n",
    "all\n",
    "Скор на обучающей выборке: 0.8797801294147838\n",
    "Скор на тестовой выборке: 0.7747975750564811\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hyperopt import hp, tpe, space_eval\n",
    "from hyperopt.fmin import fmin\n",
    "\n",
    "def function(params):\n",
    "    params = {\n",
    "        'learning_rate': params['learning_rate'], \n",
    "        'max_depth': params['max_depth'], \n",
    "        'subsample': params['subsample'], # Доля фичей\n",
    "        'colsample_bytree': params['colsample_bytree'] # Доля объектов\n",
    "    }\n",
    "    \n",
    "    print(\"############## RUN ################\")\n",
    "    print(\"params = {params}\".format(params=params))\n",
    "    \n",
    "    LGBM = LGBMClassifier(\n",
    "        n_jobs=-1, \n",
    "        n_estimators=500,\n",
    "        verbose=200,\n",
    "        **params)\n",
    "    \n",
    "    LGBM.fit(Xtrain_transform, y_train)\n",
    "    pred = LGBM.predict_proba(X_test_transform)[:, 1]\n",
    "    score = roc_auc_score(y_test, pred)\n",
    "    print(\"Score: {score}\".format(score=str(score)))\n",
    "    \n",
    "    return -score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_space =  {\n",
    "            'learning_rate': hp.quniform('learning_rate', 0.1, 0.5, 0.1),\n",
    "            'max_depth':  hp.choice('max_depth', np.arange(1, 14, dtype=int)),\n",
    "            'subsample': hp.quniform('subsample', 0.5, 1, 0.1),\n",
    "            'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############## RUN ################                 \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.4, 'colsample_bytree': 0.6000000000000001, 'max_depth': 11}\n",
      "Score: 0.5147340225513882                           \n",
      "############## RUN ################                                       \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.1, 'colsample_bytree': 0.9, 'max_depth': 4}\n",
      "Score: 0.5297093997600894                                                 \n",
      "############## RUN ################                                       \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.2, 'colsample_bytree': 0.9, 'max_depth': 8}\n",
      "Score: 0.5286196969463924                                                \n",
      "############## RUN ################                                      \n",
      "params = {'subsample': 0.5, 'learning_rate': 0.5, 'colsample_bytree': 0.6000000000000001, 'max_depth': 7}\n",
      "Score: 0.5237026489147316                                                \n",
      "############## RUN ################                                      \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.4, 'colsample_bytree': 0.7000000000000001, 'max_depth': 1}\n",
      "Score: 0.5251068773906442                                                \n",
      "############## RUN ################                                      \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.5, 'colsample_bytree': 1.0, 'max_depth': 2}\n",
      "Score: 0.5143281260393794                                                \n",
      "############## RUN ################                                      \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.5, 'colsample_bytree': 0.6000000000000001, 'max_depth': 6}\n",
      "Score: 0.5236600249903347                                                \n",
      "############## RUN ################                                      \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.6000000000000001, 'max_depth': 9}\n",
      "Score: 0.5389703999109928                                                \n",
      "############## RUN ################                                       \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.5, 'colsample_bytree': 0.9, 'max_depth': 10}\n",
      "Score: 0.528793053310047                                                  \n",
      "############## RUN ################                                       \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.4, 'colsample_bytree': 0.6000000000000001, 'max_depth': 1}\n",
      "Score: 0.5249207682037882                                                 \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.1, 'colsample_bytree': 0.5, 'max_depth': 11}\n",
      "Score: 0.5305447247015478                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.4, 'colsample_bytree': 0.6000000000000001, 'max_depth': 7}\n",
      "Score: 0.5139474491071668                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.2, 'colsample_bytree': 0.6000000000000001, 'max_depth': 2}\n",
      "Score: 0.5247262958139671                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.4, 'colsample_bytree': 0.9, 'max_depth': 6}\n",
      "Score: 0.5177893105726201                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.4, 'colsample_bytree': 0.7000000000000001, 'max_depth': 10}\n",
      "Score: 0.5189241746823281                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.2, 'colsample_bytree': 1.0, 'max_depth': 9}\n",
      "Score: 0.5262702025152374                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.2, 'colsample_bytree': 1.0, 'max_depth': 2}\n",
      "Score: 0.5307316574728583                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.7000000000000001, 'max_depth': 8}\n",
      "Score: 0.5296446886199275                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.6000000000000001, 'learning_rate': 0.1, 'colsample_bytree': 0.7000000000000001, 'max_depth': 13}\n",
      "Score: 0.5250270641542573                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.6000000000000001, 'max_depth': 9}\n",
      "Score: 0.5389703999109928                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.5, 'max_depth': 9}\n",
      "Score: 0.5373460582029943                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.5, 'max_depth': 9}\n",
      "Score: 0.5373460582029943                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.8, 'max_depth': 5}\n",
      "Score: 0.5424100269088749                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.8, 'max_depth': 5}\n",
      "Score: 0.5424100269088749                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.2, 'colsample_bytree': 0.8, 'max_depth': 5}\n",
      "Score: 0.5236899999376271                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.8, 'max_depth': 5}\n",
      "Score: 0.5424100269088749                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.8, 'max_depth': 5}\n",
      "Score: 0.5424100269088749                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.2, 'colsample_bytree': 0.8, 'max_depth': 3}\n",
      "Score: 0.5243887130526282                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.4, 'colsample_bytree': 0.8, 'max_depth': 12}\n",
      "Score: 0.5188648034521578                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.9, 'max_depth': 5}\n",
      "Score: 0.5306179185656542                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.2, 'colsample_bytree': 0.8, 'max_depth': 4}\n",
      "Score: 0.5235713841825871                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.1, 'colsample_bytree': 0.9, 'max_depth': 5}\n",
      "Score: 0.5300175627262265                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.5, 'learning_rate': 0.4, 'colsample_bytree': 0.7000000000000001, 'max_depth': 5}\n",
      "Score: 0.5294113986896908                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.9, 'max_depth': 12}\n",
      "Score: 0.5257393961297213                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.2, 'colsample_bytree': 0.8, 'max_depth': 13}\n",
      "Score: 0.5204640490200603                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.7000000000000001, 'max_depth': 3}\n",
      "Score: 0.5214442725758884                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.5, 'colsample_bytree': 0.8, 'max_depth': 4}\n",
      "Score: 0.5249901132311063                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.4, 'colsample_bytree': 1.0, 'max_depth': 11}\n",
      "Score: 0.5214833729173102                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.2, 'colsample_bytree': 0.9, 'max_depth': 8}\n",
      "Score: 0.5286196969463924                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.5, 'learning_rate': 0.1, 'colsample_bytree': 0.7000000000000001, 'max_depth': 7}\n",
      "Score: 0.5304990820560183                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.8, 'max_depth': 1}\n",
      "Score: 0.5269964413771313                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.5, 'colsample_bytree': 0.9, 'max_depth': 5}\n",
      "Score: 0.5286098198110203                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.4, 'colsample_bytree': 1.0, 'max_depth': 6}\n",
      "Score: 0.5245086350478814                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 1.0, 'learning_rate': 0.4, 'colsample_bytree': 0.9, 'max_depth': 10}\n",
      "Score: 0.5195284172395102                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 0.7000000000000001, 'max_depth': 11}\n",
      "Score: 0.5240437226030402                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.5, 'colsample_bytree': 0.9, 'max_depth': 5}\n",
      "Score: 0.5286098198110203                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.2, 'colsample_bytree': 0.7000000000000001, 'max_depth': 1}\n",
      "Score: 0.5284772214076181                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.9, 'learning_rate': 0.4, 'colsample_bytree': 0.8, 'max_depth': 7}\n",
      "Score: 0.5235624775836933                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.7000000000000001, 'learning_rate': 0.2, 'colsample_bytree': 0.7000000000000001, 'max_depth': 2}\n",
      "Score: 0.5203443797822883                                                  \n",
      "############## RUN ################                                        \n",
      "params = {'subsample': 0.8, 'learning_rate': 0.30000000000000004, 'colsample_bytree': 1.0, 'max_depth': 13}\n",
      "Score: 0.5258167190191416                                                  \n",
      "100%|██████████| 50/50 [35:28<00:00, 44.15s/it, best loss: -0.542410026909]\n"
     ]
    }
   ],
   "source": [
    "best = fmin(fn=function,\n",
    "            space=lgbm_space,\n",
    "            # tpe - Tree of Parzen Estimators (TPE)\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8,\n",
       " 'learning_rate': 0.30000000000000004,\n",
       " 'max_depth': 5,\n",
       " 'subsample': 0.9}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = space_eval(lgbm_space, best)\n",
    "#best_params['max_depth'] = int(best_params['max_depth'])\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../data/cat_in_the_dat_V1.dill', 'wb') as f:\n",
    "        dill.dump(pipe, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
